{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def txt_reader(_path):\n",
    "    file = open(_path, 'r')  # Open the file in read mode\n",
    "    contents = file.read()  # Read the contents of the file\n",
    "    file.close()  # Close the file\n",
    "\n",
    "    return contents\n",
    "\n",
    "\n",
    "def table_creator(contents):\n",
    "    record_list = []\n",
    "    weeks = contents.split(\"WEEK\")\n",
    "    pos = weeks[0].index(\"League\")\n",
    "    league_no = int(weeks[0][(pos + 7): (pos + 11)])\n",
    "    for val in weeks[1:]:\n",
    "        scores = val.split(\"\\n\")[1:-1]\n",
    "        for score in scores:\n",
    "            home_t = score[0:3]\n",
    "            away_t = score[8:11]\n",
    "            \n",
    "            # Update names of new teams to old ones\n",
    "            home_t = \"BUR\" if home_t == \"LEE\" else \"LUT\" if home_t == \"LEI\" else \"SHU\" if home_t == \"SOU\" else home_t\n",
    "            away_t = \"BUR\" if away_t == \"LEE\" else \"LUT\" if away_t == \"LEI\" else \"SHU\" if away_t == \"SOU\" else away_t\n",
    "\n",
    "            temp_dict = {\n",
    "                # \"league_id\": league_no,\n",
    "                \"week\": int((val[:3]).strip()),\n",
    "                # \"hour\": int(val.split(\"\\n\")[0][-8:-6]),\n",
    "                # \"minute\": int(val.split(\"\\n\")[0][-5:-3]),\n",
    "\n",
    "                \"HT\": home_t,\n",
    "                \"AT\": away_t,\n",
    "                \"HCS\": int(score[4]),\n",
    "                \"ACS\": int(score[6])\n",
    "            }\n",
    "\n",
    "            # data._append(temp_dict, ignore_index=True)\n",
    "            record_list.append(temp_dict)\n",
    "    data = pd.DataFrame(record_list)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Team:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.goals_for = 0\n",
    "        self.goals_against = 0\n",
    "        self.goal_difference = 0\n",
    "        self.points = 0\n",
    "        self.position = 0\n",
    "        self.last_scores = []  # List to store last scores\n",
    "        self.last_1_scores = 0\n",
    "        self.last_2_scores = 0\n",
    "        self.last_results = []  # List to store last results\n",
    "        self.last_1_result = 0\n",
    "        self.last_2_result = 0\n",
    "        self.matches_played = 0\n",
    "        self.wins = 0\n",
    "        self.losses = 0\n",
    "        self.draws = 0\n",
    "        self.win_lose_ratio = 0\n",
    "        self.pts_per_game = 0\n",
    "\n",
    "def update_table(team_1, team_1_score, team_2, team_2_score):\n",
    "    team1 = next(team for team in team_objects if team.name == team_1)\n",
    "    team2 = next(team for team in team_objects if team.name == team_2)\n",
    "\n",
    "    scores = [team_1_score, team_2_score]\n",
    "    new_teams = [team1, team2]\n",
    "\n",
    "    for i, team in enumerate(new_teams):\n",
    "        team.goals_for += scores[i]\n",
    "        team.goals_against += scores[1 - i]\n",
    "        team.goal_difference = team.goals_for - team.goals_against\n",
    "        team.points += 3 if scores[i] > scores[1 - i] else 1 if scores[i] == scores[1 - i] else 0\n",
    "\n",
    "        team.last_scores.append(scores[i])\n",
    "        team.last_1_scores = team.last_scores[-1]\n",
    "        team.last_2_scores = team.last_scores[-2] if len(team.last_scores) > 1 else 1000\n",
    "\n",
    "        team.last_results.append(1 if scores[i] > scores[1 - i] else 0 if scores[i] == scores[1 - i] else -1)\n",
    "        team.last_1_result = team.last_results[-1]\n",
    "        team.last_2_result = team.last_results[-2] if len(team.last_results) > 1 else 1000\n",
    "        \n",
    "        team.matches_played += 1 \n",
    "        team.wins += 1 if scores[i] > scores[1 - i] else 0\n",
    "        team.losses += 1 if scores[i] < scores[1 - i] else 0\n",
    "        team.draws += 1 if scores[i] == scores[1 - i] else 0\n",
    "        team.win_lose_ratio = team.wins / team.matches_played if team.matches_played > 0 else 0.0\n",
    "        team.pts_per_game = team.points / team.matches_played if team.matches_played > 0 else 0.0\n",
    "\n",
    "    table = sorted(team_objects, key=lambda x: (-x.points, x.name.lower()))\n",
    "\n",
    "    for i, team in enumerate(table):\n",
    "        team.position = i + 1\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def get_record(table_objects):\n",
    "    table_dict = dict()\n",
    "    for team in table_objects:\n",
    "        table_dict[team.name] = (\n",
    "            team.goals_for,\n",
    "            team.goals_against,\n",
    "            team.goal_difference,\n",
    "            team.points,\n",
    "            team.position,\n",
    "            team.last_1_scores,\n",
    "            # team.last_2_scores,\n",
    "            team.last_1_result,\n",
    "            # team.last_2_result,\n",
    "            team.wins,\n",
    "            team.losses,\n",
    "            team.draws,\n",
    "            team.win_lose_ratio,\n",
    "            team.pts_per_game\n",
    "        )\n",
    "\n",
    "    return table_dict\n",
    "\n",
    "\n",
    "def add_features(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    col_list = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        ht, hcs, at, acs = row[\"HT\"], row[\"HCS\"], row[\"AT\"], row[\"ACS\"]\n",
    "\n",
    "        table = update_table(ht, hcs, at, acs)\n",
    "\n",
    "        if row[\"week\"] > 1:\n",
    "            col_list.append(table_dict[ht] + table_dict[at])\n",
    "        else:\n",
    "            col_list.append((0,) * 24)\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            table_dict = get_record(table)\n",
    "\n",
    "    # Create a DataFrame from the list of tuples\n",
    "    new_df = pd.DataFrame(col_list, columns=[\n",
    "        \"h_gf\", \"h_ga\", \"h_gd\", \"h_pts\", \"h_pos\", \"HL1S\", \"HL1R\", \"H_win\", \"H_loss\", \"H_draws\", \"H_wlr\", \"H_ppg\", \n",
    "        \"a_gf\", \"a_ga\", \"a_gd\", \"a_pts\", \"a_pos\", \"AL1S\", \"AL1R\", \"A_win\", \"A_loss\", \"A_draws\", \"A_wlr\", \"A_ppg\"])\n",
    "\n",
    "    # Concatenate the new DataFrame with the existing DataFrame\n",
    "    df = pd.concat([df, new_df], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"league_data\"\n",
    "records = [\n",
    "    f\"{path}/L_6095.txt\", f\"{path}/L_6097.txt\", f\"{path}/L_6099.txt\",\n",
    "    f\"{path}/L_6148.txt\", f\"{path}/L_6152.txt\", f\"{path}/L_6153.txt\",\n",
    "    f\"{path}/L_6155.txt\", f\"{path}/L_6156.txt\", f\"{path}/L_6166.txt\",\n",
    "    f\"{path}/L_6169.txt\", f\"{path}/L_6170.txt\", f\"{path}/L_6171.txt\",\n",
    "    f\"{path}/L_6173.txt\", f\"{path}/L_6180.txt\", f\"{path}/L_6181.txt\",\n",
    "    f\"{path}/L_6189.txt\", f\"{path}/L_6192.txt\", f\"{path}/L_6211.txt\",\n",
    "    f\"{path}/L_6212.txt\", f\"{path}/L_6213.txt\", f\"{path}/L_6214.txt\",\n",
    "    f\"{path}/L_6215.txt\", f\"{path}/L_6216.txt\", f\"{path}/L_6226.txt\", \n",
    "    f\"{path}/L_6227.txt\", f\"{path}/L_6230.txt\", f\"{path}/LN_1575.txt\",\n",
    "    f\"{path}/LN_1576.txt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "         'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "# teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "#          'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "\n",
    "\n",
    "df_temp = []\n",
    "for record in records:\n",
    "    text = txt_reader(record)  # read each txt data\n",
    "    new_df = table_creator(text)  # convert each txt data to a dataframe\n",
    "    \n",
    "    # create a new empty league table to record scores & points\n",
    "    team_objects = [Team(team) for team in teams]\n",
    "\n",
    "    # adds scores & points from each league to the dataframe\n",
    "    new_df = add_features(new_df)\n",
    "\n",
    "    df_temp.append(new_df)  # add each dataframe to a list\n",
    "\n",
    "df_records = pd.concat(df_temp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_records[[\"HT\", \"AT\", \"HCS\", \"ACS\", \"HL1S\", \"HL1R\", \"AL1S\", \"AL1R\"]].iloc[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check home and away scores and return result\n",
    "def get_result(row):\n",
    "    if row['HCS'] + row['ACS'] > 3:\n",
    "        return 1  # home_win = 1\n",
    "    else:\n",
    "        return 0  # draw = 0\n",
    "        \n",
    "\n",
    "def feature_engineering(data):\n",
    "    df_result = data.copy()\n",
    "        \n",
    "    # Apply function to each row of the dataframe to create a new column\n",
    "    df_result['result'] = df_result.apply(get_result, axis=1)\n",
    "\n",
    "    df_result = df_result[df_result['week'] > 3]  # remove rows with incomplete values\n",
    "\n",
    "    # Create a LabelEncoder object\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit the LabelEncoder on the unique team names\n",
    "    label_encoder.fit(teams)\n",
    "\n",
    "    # Convert the categorical features to numeric using label encoding\n",
    "    df_result['HT_encoded'] = label_encoder.transform(df_result['HT'])\n",
    "    df_result['AT_encoded'] = label_encoder.transform(df_result['AT'])\n",
    "\n",
    "    # remove irrelevant features\n",
    "    df_result = df_result.drop([\"HCS\", \"ACS\", \"HT\", \"AT\"], axis=1)  \n",
    "\n",
    "    df_result = df_result.reset_index(drop=True)  # reset the index values\n",
    "\n",
    "    # Scaling the dataset using standardization method\n",
    "    X = df_result.drop(\"result\", axis=1)\n",
    "    y = df_result[\"result\"]\n",
    "\n",
    "    # assume that X is your dataset with numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # # concatenate the scaled numerical features with the Target variable feature\n",
    "    data_preprocessed = pd.concat([pd.DataFrame(X_scaled, columns=X.columns), y], axis=1)\n",
    "\n",
    "    return data_preprocessed\n",
    "\n",
    "\n",
    "processed_df = feature_engineering(df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>h_gf</th>\n",
       "      <th>h_ga</th>\n",
       "      <th>h_gd</th>\n",
       "      <th>h_pts</th>\n",
       "      <th>h_pos</th>\n",
       "      <th>HL1S</th>\n",
       "      <th>HL1R</th>\n",
       "      <th>H_win</th>\n",
       "      <th>H_loss</th>\n",
       "      <th>H_draws</th>\n",
       "      <th>H_wlr</th>\n",
       "      <th>H_ppg</th>\n",
       "      <th>a_gf</th>\n",
       "      <th>a_ga</th>\n",
       "      <th>a_gd</th>\n",
       "      <th>a_pts</th>\n",
       "      <th>a_pos</th>\n",
       "      <th>AL1S</th>\n",
       "      <th>AL1R</th>\n",
       "      <th>A_win</th>\n",
       "      <th>A_loss</th>\n",
       "      <th>A_draws</th>\n",
       "      <th>A_wlr</th>\n",
       "      <th>A_ppg</th>\n",
       "      <th>HT_encoded</th>\n",
       "      <th>AT_encoded</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.683251</td>\n",
       "      <td>-1.208772</td>\n",
       "      <td>-1.449428</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>-1.281173</td>\n",
       "      <td>-0.789747</td>\n",
       "      <td>0.697362</td>\n",
       "      <td>-1.063136</td>\n",
       "      <td>-1.073186</td>\n",
       "      <td>-1.321738</td>\n",
       "      <td>-1.578042</td>\n",
       "      <td>1.753668</td>\n",
       "      <td>1.336123</td>\n",
       "      <td>-1.530901</td>\n",
       "      <td>-1.574698</td>\n",
       "      <td>-0.008488</td>\n",
       "      <td>-1.289979</td>\n",
       "      <td>-1.118814</td>\n",
       "      <td>-0.377747</td>\n",
       "      <td>1.062088</td>\n",
       "      <td>-1.081913</td>\n",
       "      <td>-1.313126</td>\n",
       "      <td>-1.580799</td>\n",
       "      <td>1.735934</td>\n",
       "      <td>1.320169</td>\n",
       "      <td>0.605928</td>\n",
       "      <td>-1.124241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.683251</td>\n",
       "      <td>-1.463318</td>\n",
       "      <td>-1.449428</td>\n",
       "      <td>-0.067579</td>\n",
       "      <td>-1.401666</td>\n",
       "      <td>-0.270699</td>\n",
       "      <td>-1.108702</td>\n",
       "      <td>-1.063136</td>\n",
       "      <td>-1.275215</td>\n",
       "      <td>-1.321738</td>\n",
       "      <td>-1.281940</td>\n",
       "      <td>-0.185329</td>\n",
       "      <td>-0.058640</td>\n",
       "      <td>-1.276676</td>\n",
       "      <td>-1.640376</td>\n",
       "      <td>0.372374</td>\n",
       "      <td>-1.289979</td>\n",
       "      <td>-0.944961</td>\n",
       "      <td>2.903372</td>\n",
       "      <td>1.062088</td>\n",
       "      <td>-1.081913</td>\n",
       "      <td>-1.313126</td>\n",
       "      <td>-1.580799</td>\n",
       "      <td>1.735934</td>\n",
       "      <td>1.320169</td>\n",
       "      <td>-0.609401</td>\n",
       "      <td>0.434799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.683251</td>\n",
       "      <td>-1.272408</td>\n",
       "      <td>-1.514994</td>\n",
       "      <td>0.236635</td>\n",
       "      <td>-1.220926</td>\n",
       "      <td>-1.481811</td>\n",
       "      <td>-0.205670</td>\n",
       "      <td>1.288192</td>\n",
       "      <td>-1.073186</td>\n",
       "      <td>-1.529605</td>\n",
       "      <td>-1.281940</td>\n",
       "      <td>1.753668</td>\n",
       "      <td>2.033504</td>\n",
       "      <td>-1.721569</td>\n",
       "      <td>-1.706055</td>\n",
       "      <td>-0.084660</td>\n",
       "      <td>-1.531059</td>\n",
       "      <td>1.141273</td>\n",
       "      <td>-1.198027</td>\n",
       "      <td>-0.112417</td>\n",
       "      <td>-1.485850</td>\n",
       "      <td>-1.313126</td>\n",
       "      <td>-0.987947</td>\n",
       "      <td>-2.150599</td>\n",
       "      <td>-1.485995</td>\n",
       "      <td>0.779547</td>\n",
       "      <td>0.088346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       week      h_gf      h_ga      h_gd     h_pts     h_pos      HL1S  \\\n",
       "0 -1.683251 -1.208772 -1.449428  0.236635 -1.281173 -0.789747  0.697362   \n",
       "1 -1.683251 -1.463318 -1.449428 -0.067579 -1.401666 -0.270699 -1.108702   \n",
       "2 -1.683251 -1.272408 -1.514994  0.236635 -1.220926 -1.481811 -0.205670   \n",
       "\n",
       "       HL1R     H_win    H_loss   H_draws     H_wlr     H_ppg      a_gf  \\\n",
       "0 -1.063136 -1.073186 -1.321738 -1.578042  1.753668  1.336123 -1.530901   \n",
       "1 -1.063136 -1.275215 -1.321738 -1.281940 -0.185329 -0.058640 -1.276676   \n",
       "2  1.288192 -1.073186 -1.529605 -1.281940  1.753668  2.033504 -1.721569   \n",
       "\n",
       "       a_ga      a_gd     a_pts     a_pos      AL1S      AL1R     A_win  \\\n",
       "0 -1.574698 -0.008488 -1.289979 -1.118814 -0.377747  1.062088 -1.081913   \n",
       "1 -1.640376  0.372374 -1.289979 -0.944961  2.903372  1.062088 -1.081913   \n",
       "2 -1.706055 -0.084660 -1.531059  1.141273 -1.198027 -0.112417 -1.485850   \n",
       "\n",
       "     A_loss   A_draws     A_wlr     A_ppg  HT_encoded  AT_encoded  result  \n",
       "0 -1.313126 -1.580799  1.735934  1.320169    0.605928   -1.124241       0  \n",
       "1 -1.313126 -1.580799  1.735934  1.320169   -0.609401    0.434799       0  \n",
       "2 -1.313126 -0.987947 -2.150599 -1.485995    0.779547    0.088346       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7030612244897959\n",
      "F1 score: 0.6074031417366847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "dataset = processed_df.copy()\n",
    "\n",
    "# Load your dataset into X and y arrays\n",
    "X = dataset.drop(\"result\", axis=1)\n",
    "y = dataset[\"result\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIN % - 93.89999999999999\n"
     ]
    }
   ],
   "source": [
    "num = 1000\n",
    "actual_vals = processed_df[\"result\"].head(num)\n",
    "\n",
    "data = processed_df.drop(\"result\", axis=1).head(num)\n",
    "pred_vals = rf_model.predict(data).tolist()\n",
    "\n",
    "count = 0\n",
    "for x, y in zip(actual_vals, pred_vals):\n",
    "    if x == y:\n",
    "        count += 1\n",
    "        \n",
    "print(\"WIN % -\", (count/num) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# team = {\"BUR\": \"LEE\", \"LUT\": \"LEI\", \"SHU\": \"SOU\"}.get(team, team)\n",
    "# print(team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL',\n",
    "#          'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "# # teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL',\n",
    "# #          'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "\n",
    "# path = \"league_data\"\n",
    "# stake_records = [f\"{path}/LN_1570.txt\"]\n",
    "\n",
    "# rec_list = []\n",
    "# for test_record in stake_records:\n",
    "#     # create a new empty league table to record scores & points\n",
    "#     team_objects = [Team(team) for team in teams]\n",
    "\n",
    "#     text = txt_reader(test_record)  # read each txt data\n",
    "\n",
    "#     # adds scores & points from each league to the dataframe\n",
    "#     new_df = add_features(table_creator(text))\n",
    "\n",
    "#     rec_list.append(new_df)\n",
    "\n",
    "# records_df = pd.concat(rec_list, axis=0)\n",
    "\n",
    "# all_process_df = feature_engineering(records_df)\n",
    "# all_process_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num = 360\n",
    "# data = all_process_df.drop(\"result\", axis=1).iloc[50:num]\n",
    "# pred_results = rf_model.predict(data).tolist()\n",
    "\n",
    "# actual_results = all_process_df[\"result\"].iloc[50:num].tolist()\n",
    "\n",
    "# total_played, total_won = 0, 0\n",
    "# for x, y in zip(actual_results, pred_results):\n",
    "#     if x == y and x == 1:\n",
    "#         print(x, y)\n",
    "#     if y == 1:\n",
    "#         total_played += 1\n",
    "#         if x == y:\n",
    "#             total_won += 1\n",
    "# print(f\"{total_won} / {total_played}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOL - NWC = 0\n",
      "BUR - FOR = 0\n",
      "BRN - TOT = 0\n",
      "BRI - SHU = 0\n",
      "MNC - MNU = 0\n",
      "EVE - CHE = 0\n",
      "CRY - BOU = 0\n",
      "WHU - ASV = 0\n",
      "LUT - LIV = 0\n",
      "FUL - ARS = 0\n"
     ]
    }
   ],
   "source": [
    "teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL',\n",
    "         'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "stake_teams = txt_reader(\"league_data/stake_teams.txt\")\n",
    "new_week = int(stake_teams.split(\"\\n\")[4].split(\"WEEK\")[1].strip())\n",
    "stake_teams = stake_teams.split(\"\\n\")[5:-9][0:31:3][1:]\n",
    "stake_vals = []\n",
    "for club in stake_teams:\n",
    "    club = club.strip()\n",
    "    h_team = club[:4].strip()\n",
    "    a_team = club[6:10].strip()\n",
    "    stake_vals.append((new_week, h_team, a_team, 0, 0))\n",
    "stake_teams_df = pd.DataFrame(stake_vals, columns=[\"week\", \"HT\", \"AT\", \"HCS\", \"ACS\"])\n",
    "\n",
    "\n",
    "team_objects = [Team(team) for team in teams]\n",
    "\n",
    "stake_df = table_creator(txt_reader(\"league_data/LN_1570.txt\"))\n",
    "merge_df = pd.concat([stake_df, stake_teams_df], axis=0, ignore_index=True)\n",
    "merge_df = add_features(merge_df)\n",
    "\n",
    "process_df = feature_engineering(merge_df)\n",
    "\n",
    "pred_data = process_df.drop(\"result\", axis=1).tail(10)\n",
    "pred_vals = rf_model.predict(pred_data).tolist()\n",
    "\n",
    "home = merge_df[\"HT\"].tail(10)\n",
    "away = merge_df[\"AT\"].tail(10)\n",
    "\n",
    "for x, y, z in zip(home, away, pred_vals):\n",
    "    print(x, \"-\", y, \"=\", z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# # Load your dataset into a pandas DataFrame\n",
    "# dataset = processed_df.copy()\n",
    "\n",
    "# # Load your dataset into X and y arrays\n",
    "# X = dataset.drop(\"result\", axis=1)\n",
    "# y = dataset[\"result\"]\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define a dictionary to store the models\n",
    "# models = {\n",
    "#     'Random Forest': RandomForestClassifier(random_state=42),\n",
    "#     'SVC': SVC(random_state=42),\n",
    "#     'XGBoost': XGBClassifier(random_state=42),\n",
    "#     'Gradient Boost': GradientBoostingClassifier(random_state=42),\n",
    "#     'Logistic Regression': LogisticRegression(random_state=42),\n",
    "#     # 'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "# }\n",
    "\n",
    "# # Calculate the F1 scores for each model\n",
    "# model_scores = []\n",
    "# for model_name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "#     f1 = round(f1_score(y_test, y_pred, average='weighted'), 3)\n",
    "#     model_scores.append((model_name, f1))\n",
    "#     print(f'{model_name}:')\n",
    "#     print('Accuracy:', accuracy)\n",
    "#     print('F1 score:', f1)\n",
    "#     print('-' * 40)\n",
    "\n",
    "# # Sort the models based on F1 scores in descending order\n",
    "# model_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "# model_names, f1_scores = zip(*model_scores)\n",
    "\n",
    "# # Plot the horizontal bar graph\n",
    "# plt.figure(figsize=(12, 7))\n",
    "# plt.barh(model_names, f1_scores)  # <-- Use plt.barh() for horizontal bars\n",
    "# plt.ylabel('Model')\n",
    "# plt.xlabel('F1 Score')\n",
    "# plt.title('F1 Scores of Different Models')\n",
    "\n",
    "# # Add the scores beside each bar\n",
    "# for i, score in enumerate(f1_scores):\n",
    "#     plt.text(score, i, f'{score:.3f}', ha='left', va='center')  # <-- Adjust text position\n",
    "\n",
    "# # Display the horizontal bar graph\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
