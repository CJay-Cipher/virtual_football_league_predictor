{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def txt_reader(_path):\n",
    "    file = open(_path, 'r')  # Open the file in read mode\n",
    "    contents = file.read()  # Read the contents of the file\n",
    "    file.close()  # Close the file\n",
    "\n",
    "    return contents\n",
    "\n",
    "\n",
    "def table_creator(contents):\n",
    "    record_list = []\n",
    "    weeks = contents.split(\"WEEK\")\n",
    "    pos = weeks[0].index(\"League\")\n",
    "    league_no = int(weeks[0][(pos + 7): (pos + 11)])\n",
    "    for val in weeks[1:]:\n",
    "        scores = val.split(\"\\n\")[1:-1]\n",
    "        for score in scores:\n",
    "            home_t = score[0:3]\n",
    "            away_t = score[8:11]\n",
    "            \n",
    "            # Update names of new teams to old ones\n",
    "            home_t = \"BUR\" if home_t == \"LEE\" else \"LUT\" if home_t == \"LEI\" else \"SHU\" if home_t == \"SOU\" else home_t\n",
    "            away_t = \"BUR\" if away_t == \"LEE\" else \"LUT\" if away_t == \"LEI\" else \"SHU\" if away_t == \"SOU\" else away_t\n",
    "\n",
    "            temp_dict = {\n",
    "                # \"league_id\": league_no,\n",
    "                \"week\": int((val[:3]).strip()),\n",
    "                # \"hour\": int(val.split(\"\\n\")[0][-8:-6]),\n",
    "                # \"minute\": int(val.split(\"\\n\")[0][-5:-3]),\n",
    "\n",
    "                \"HT\": home_t,\n",
    "                \"AT\": away_t,\n",
    "                \"HCS\": int(score[4]),\n",
    "                \"ACS\": int(score[6])\n",
    "            }\n",
    "\n",
    "            # data._append(temp_dict, ignore_index=True)\n",
    "            record_list.append(temp_dict)\n",
    "    data = pd.DataFrame(record_list)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Team:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.goals_for = 0\n",
    "        self.goals_against = 0\n",
    "        self.goal_difference = 0\n",
    "        self.points = 0\n",
    "        self.position = 0\n",
    "        self.last_scores = []  # List to store last scores\n",
    "        self.last_1_scores = 0\n",
    "        self.last_2_scores = 0\n",
    "        self.last_results = []  # List to store last results\n",
    "        self.last_1_result = 0\n",
    "        self.last_2_result = 0\n",
    "        self.matches_played = 0\n",
    "        self.wins = 0\n",
    "        self.losses = 0\n",
    "        self.draws = 0\n",
    "        self.win_lose_ratio = 0\n",
    "        self.pts_per_game = 0\n",
    "\n",
    "def update_table(team_1, team_1_score, team_2, team_2_score):\n",
    "    team1 = next(team for team in team_objects if team.name == team_1)\n",
    "    team2 = next(team for team in team_objects if team.name == team_2)\n",
    "\n",
    "    scores = [team_1_score, team_2_score]\n",
    "    new_teams = [team1, team2]\n",
    "\n",
    "    for i, team in enumerate(new_teams):\n",
    "        team.goals_for += scores[i]\n",
    "        team.goals_against += scores[1 - i]\n",
    "        team.goal_difference = team.goals_for - team.goals_against\n",
    "        team.points += 3 if scores[i] > scores[1 - i] else 1 if scores[i] == scores[1 - i] else 0\n",
    "\n",
    "        team.last_scores.append(scores[i])\n",
    "        team.last_1_scores = team.last_scores[-1]\n",
    "        team.last_2_scores = team.last_scores[-2] if len(team.last_scores) > 1 else 1000\n",
    "\n",
    "        team.last_results.append(1 if scores[i] > scores[1 - i] else 0 if scores[i] == scores[1 - i] else -1)\n",
    "        team.last_1_result = team.last_results[-1]\n",
    "        team.last_2_result = team.last_results[-2] if len(team.last_results) > 1 else 1000\n",
    "        \n",
    "        team.matches_played += 1 \n",
    "        team.wins += 1 if scores[i] > scores[1 - i] else 0\n",
    "        team.losses += 1 if scores[i] < scores[1 - i] else 0\n",
    "        team.draws += 1 if scores[i] == scores[1 - i] else 0\n",
    "        team.win_lose_ratio = team.wins / team.matches_played if team.matches_played > 0 else 0.0\n",
    "        team.pts_per_game = team.points / team.matches_played if team.matches_played > 0 else 0.0\n",
    "\n",
    "    table = sorted(team_objects, key=lambda x: (-x.points, x.name.lower()))\n",
    "\n",
    "    for i, team in enumerate(table):\n",
    "        team.position = i + 1\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def get_record(table_objects):\n",
    "    table_dict = dict()\n",
    "    for team in table_objects:\n",
    "        table_dict[team.name] = (\n",
    "            team.goals_for,\n",
    "            team.goals_against,\n",
    "            team.goal_difference,\n",
    "            team.points,\n",
    "            team.position,\n",
    "            team.last_1_scores,\n",
    "            # team.last_2_scores,\n",
    "            team.last_1_result,\n",
    "            # team.last_2_result,\n",
    "            team.wins,\n",
    "            team.losses,\n",
    "            team.draws,\n",
    "            team.win_lose_ratio,\n",
    "            team.pts_per_game\n",
    "        )\n",
    "\n",
    "    return table_dict\n",
    "\n",
    "\n",
    "def add_features(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    col_list = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        ht, hcs, at, acs = row[\"HT\"], row[\"HCS\"], row[\"AT\"], row[\"ACS\"]\n",
    "\n",
    "        table = update_table(ht, hcs, at, acs)\n",
    "\n",
    "        if row[\"week\"] > 1:\n",
    "            col_list.append(table_dict[ht] + table_dict[at])\n",
    "        else:\n",
    "            col_list.append((0,) * 24)\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            table_dict = get_record(table)\n",
    "\n",
    "    # Create a DataFrame from the list of tuples\n",
    "    new_df = pd.DataFrame(col_list, columns=[\n",
    "        \"h_gf\", \"h_ga\", \"h_gd\", \"h_pts\", \"h_pos\", \"HL1S\", \"HL1R\", \"H_win\", \"H_loss\", \"H_draws\", \"H_wlr\", \"H_ppg\", \n",
    "        \"a_gf\", \"a_ga\", \"a_gd\", \"a_pts\", \"a_pos\", \"AL1S\", \"AL1R\", \"A_win\", \"A_loss\", \"A_draws\", \"A_wlr\", \"A_ppg\"])\n",
    "\n",
    "    # Concatenate the new DataFrame with the existing DataFrame\n",
    "    df = pd.concat([df, new_df], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"league_data\"\n",
    "records = [\n",
    "    f\"{path}/L_6095.txt\", f\"{path}/L_6097.txt\", f\"{path}/L_6099.txt\",\n",
    "    f\"{path}/L_6148.txt\", f\"{path}/L_6152.txt\", f\"{path}/L_6153.txt\",\n",
    "    f\"{path}/L_6155.txt\", f\"{path}/L_6156.txt\", f\"{path}/L_6166.txt\",\n",
    "    f\"{path}/L_6169.txt\", f\"{path}/L_6170.txt\", f\"{path}/L_6171.txt\",\n",
    "    f\"{path}/L_6173.txt\", f\"{path}/L_6180.txt\", f\"{path}/L_6181.txt\",\n",
    "    f\"{path}/L_6189.txt\", f\"{path}/L_6192.txt\", f\"{path}/L_6211.txt\",\n",
    "    f\"{path}/L_6212.txt\", f\"{path}/L_6213.txt\", f\"{path}/L_6214.txt\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "         'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "# teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "#          'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "\n",
    "\n",
    "df_temp = []\n",
    "for record in records:\n",
    "    text = txt_reader(record)  # read each txt data\n",
    "    new_df = table_creator(text)  # convert each txt data to a dataframe\n",
    "    \n",
    "    # create a new empty league table to record scores & points\n",
    "    team_objects = [Team(team) for team in teams]\n",
    "\n",
    "    # adds scores & points from each league to the dataframe\n",
    "    new_df = add_features(new_df)\n",
    "\n",
    "    df_temp.append(new_df)  # add each dataframe to a list\n",
    "\n",
    "df_records = pd.concat(df_temp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_records[[\"HT\", \"AT\", \"HCS\", \"ACS\", \"HL1S\", \"HL1R\", \"AL1S\", \"AL1R\"]].iloc[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check home and away scores and return result\n",
    "def get_result(row):\n",
    "    if row['HCS'] + row['ACS'] > 3:\n",
    "        return 1  # home_win = 1\n",
    "    else:\n",
    "        return 0  # draw = 0\n",
    "        \n",
    "\n",
    "def feature_engineering(data):\n",
    "    df_result = data.copy()\n",
    "        \n",
    "    # Apply function to each row of the dataframe to create a new column\n",
    "    df_result['result'] = df_result.apply(get_result, axis=1)\n",
    "\n",
    "    df_result = df_result[df_result['week'] > 2]  # remove rows with incomplete values\n",
    "\n",
    "    # Create a LabelEncoder object\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit the LabelEncoder on the unique team names\n",
    "    label_encoder.fit(teams)\n",
    "\n",
    "    # Convert the categorical features to numeric using label encoding\n",
    "    df_result['HT_encoded'] = label_encoder.transform(df_result['HT'])\n",
    "    df_result['AT_encoded'] = label_encoder.transform(df_result['AT'])\n",
    "\n",
    "    # remove irrelevant features\n",
    "    df_result = df_result.drop([\"HCS\", \"ACS\", \"HT\", \"AT\"], axis=1)  \n",
    "\n",
    "    df_result = df_result.reset_index(drop=True)  # reset the index values\n",
    "\n",
    "    # Scaling the dataset using standardization method\n",
    "    X = df_result.drop(\"result\", axis=1)\n",
    "    y = df_result[\"result\"]\n",
    "\n",
    "    # assume that X is your dataset with numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # # concatenate the scaled numerical features with the Target variable feature\n",
    "    data_preprocessed = pd.concat([pd.DataFrame(X_scaled, columns=X.columns), y], axis=1)\n",
    "\n",
    "    return data_preprocessed\n",
    "\n",
    "\n",
    "processed_df = feature_engineering(df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>h_gf</th>\n",
       "      <th>h_ga</th>\n",
       "      <th>h_gd</th>\n",
       "      <th>h_pts</th>\n",
       "      <th>h_pos</th>\n",
       "      <th>HL1S</th>\n",
       "      <th>HL1R</th>\n",
       "      <th>H_win</th>\n",
       "      <th>H_loss</th>\n",
       "      <th>H_draws</th>\n",
       "      <th>H_wlr</th>\n",
       "      <th>H_ppg</th>\n",
       "      <th>a_gf</th>\n",
       "      <th>a_ga</th>\n",
       "      <th>a_gd</th>\n",
       "      <th>a_pts</th>\n",
       "      <th>a_pos</th>\n",
       "      <th>AL1S</th>\n",
       "      <th>AL1R</th>\n",
       "      <th>A_win</th>\n",
       "      <th>A_loss</th>\n",
       "      <th>A_draws</th>\n",
       "      <th>A_wlr</th>\n",
       "      <th>A_ppg</th>\n",
       "      <th>HT_encoded</th>\n",
       "      <th>AT_encoded</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.684588</td>\n",
       "      <td>-1.453786</td>\n",
       "      <td>-1.373159</td>\n",
       "      <td>-0.144947</td>\n",
       "      <td>-1.393632</td>\n",
       "      <td>-0.273942</td>\n",
       "      <td>-1.103691</td>\n",
       "      <td>-1.066926</td>\n",
       "      <td>-1.217410</td>\n",
       "      <td>-1.265724</td>\n",
       "      <td>-1.512227</td>\n",
       "      <td>0.756579</td>\n",
       "      <td>0.285594</td>\n",
       "      <td>-1.397224</td>\n",
       "      <td>-1.622153</td>\n",
       "      <td>0.221828</td>\n",
       "      <td>-1.344902</td>\n",
       "      <td>-1.114719</td>\n",
       "      <td>2.090205</td>\n",
       "      <td>1.068098</td>\n",
       "      <td>-1.227847</td>\n",
       "      <td>-1.459165</td>\n",
       "      <td>-1.224168</td>\n",
       "      <td>0.720570</td>\n",
       "      <td>1.253041</td>\n",
       "      <td>-0.433920</td>\n",
       "      <td>-1.646831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.684588</td>\n",
       "      <td>-1.516331</td>\n",
       "      <td>-1.437464</td>\n",
       "      <td>-0.144947</td>\n",
       "      <td>-1.511875</td>\n",
       "      <td>1.111689</td>\n",
       "      <td>0.698643</td>\n",
       "      <td>0.108527</td>\n",
       "      <td>-1.416385</td>\n",
       "      <td>-1.265724</td>\n",
       "      <td>-1.222380</td>\n",
       "      <td>-2.016053</td>\n",
       "      <td>-1.718686</td>\n",
       "      <td>-1.397224</td>\n",
       "      <td>-1.493529</td>\n",
       "      <td>0.068311</td>\n",
       "      <td>-1.344902</td>\n",
       "      <td>-0.941043</td>\n",
       "      <td>-0.371158</td>\n",
       "      <td>1.068098</td>\n",
       "      <td>-1.227847</td>\n",
       "      <td>-1.459165</td>\n",
       "      <td>-1.224168</td>\n",
       "      <td>0.720570</td>\n",
       "      <td>1.253041</td>\n",
       "      <td>1.127282</td>\n",
       "      <td>-0.606568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.684588</td>\n",
       "      <td>-1.391241</td>\n",
       "      <td>-1.501769</td>\n",
       "      <td>0.085134</td>\n",
       "      <td>-1.393632</td>\n",
       "      <td>-0.620349</td>\n",
       "      <td>0.698643</td>\n",
       "      <td>1.283981</td>\n",
       "      <td>-1.217410</td>\n",
       "      <td>-1.265724</td>\n",
       "      <td>-1.512227</td>\n",
       "      <td>0.756579</td>\n",
       "      <td>0.285594</td>\n",
       "      <td>-1.272098</td>\n",
       "      <td>-1.622153</td>\n",
       "      <td>0.375346</td>\n",
       "      <td>-1.226458</td>\n",
       "      <td>-1.462071</td>\n",
       "      <td>2.090205</td>\n",
       "      <td>1.068098</td>\n",
       "      <td>-1.028639</td>\n",
       "      <td>-1.459165</td>\n",
       "      <td>-1.514347</td>\n",
       "      <td>3.481057</td>\n",
       "      <td>3.259640</td>\n",
       "      <td>-1.474721</td>\n",
       "      <td>0.607072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       week      h_gf      h_ga      h_gd     h_pts     h_pos      HL1S  \\\n",
       "0 -1.684588 -1.453786 -1.373159 -0.144947 -1.393632 -0.273942 -1.103691   \n",
       "1 -1.684588 -1.516331 -1.437464 -0.144947 -1.511875  1.111689  0.698643   \n",
       "2 -1.684588 -1.391241 -1.501769  0.085134 -1.393632 -0.620349  0.698643   \n",
       "\n",
       "       HL1R     H_win    H_loss   H_draws     H_wlr     H_ppg      a_gf  \\\n",
       "0 -1.066926 -1.217410 -1.265724 -1.512227  0.756579  0.285594 -1.397224   \n",
       "1  0.108527 -1.416385 -1.265724 -1.222380 -2.016053 -1.718686 -1.397224   \n",
       "2  1.283981 -1.217410 -1.265724 -1.512227  0.756579  0.285594 -1.272098   \n",
       "\n",
       "       a_ga      a_gd     a_pts     a_pos      AL1S      AL1R     A_win  \\\n",
       "0 -1.622153  0.221828 -1.344902 -1.114719  2.090205  1.068098 -1.227847   \n",
       "1 -1.493529  0.068311 -1.344902 -0.941043 -0.371158  1.068098 -1.227847   \n",
       "2 -1.622153  0.375346 -1.226458 -1.462071  2.090205  1.068098 -1.028639   \n",
       "\n",
       "     A_loss   A_draws     A_wlr     A_ppg  HT_encoded  AT_encoded  result  \n",
       "0 -1.459165 -1.224168  0.720570  1.253041   -0.433920   -1.646831       0  \n",
       "1 -1.459165 -1.224168  0.720570  1.253041    1.127282   -0.606568       0  \n",
       "2 -1.459165 -1.514347  3.481057  3.259640   -1.474721    0.607072       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6693121693121693\n",
      "F1 score: 0.5665218109307566\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "dataset = processed_df.copy()\n",
    "\n",
    "# Load your dataset into X and y arrays\n",
    "X = dataset.drop(\"result\", axis=1)\n",
    "y = dataset[\"result\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6488095238095238\n",
      "F1 score: 0.5893227976055107\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "dataset = processed_df.copy()\n",
    "\n",
    "# Load your dataset into X and y arrays\n",
    "X = dataset.drop(\"result\", axis=1)\n",
    "y = dataset[\"result\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIN % - 92.4\n"
     ]
    }
   ],
   "source": [
    "num = 1000\n",
    "actual_vals = processed_df[\"result\"].head(num)\n",
    "\n",
    "data = processed_df.drop(\"result\", axis=1).head(num)\n",
    "pred_vals = rf_model.predict(data).tolist()\n",
    "\n",
    "count = 0\n",
    "for x, y in zip(actual_vals, pred_vals):\n",
    "    if x == y:\n",
    "        count += 1\n",
    "        \n",
    "print(\"WIN % -\", (count/num) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams_1 = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "#          'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "# teams_2 = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "#          'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "\n",
    "# for x, y in zip(sorted(teams_1), sorted(teams_2)):\n",
    "#     print(x, \"--\", y)\n",
    "\n",
    "# old_teams = [\"LEE\", \"LEI\", \"SOU\"]\n",
    "# new_teams = [\"BUR\", \"LUT\", \"SHU\"]\n",
    "\n",
    "# team = \"WOL\"\n",
    "# if team == \"BUR\":\n",
    "#     team = \"LEE\"\n",
    "# elif team == \"LUT\":\n",
    "#     team = \"LEI\"\n",
    "# elif team == \"SHU\":\n",
    "#     team = \"SOU\"\n",
    "# team = \"LEE\" if team == \"BUR\" else \"LEI\" if team == \"LUT\" else \"SOU\" if team == \"SHU\" else team\n",
    "# team = {\"BUR\": \"LEE\", \"LUT\": \"LEI\", \"SHU\": \"SOU\"}.get(team, team)\n",
    "# print(team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL',\n",
    "#          'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "# # teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL',\n",
    "# #          'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "\n",
    "# path = \"league_data\"\n",
    "# stake_records = [f\"{path}/LN_1570.txt\"]\n",
    "\n",
    "# rec_list = []\n",
    "# for test_record in stake_records:\n",
    "#     # create a new empty league table to record scores & points\n",
    "#     team_objects = [Team(team) for team in teams]\n",
    "\n",
    "#     text = txt_reader(test_record)  # read each txt data\n",
    "\n",
    "#     # adds scores & points from each league to the dataframe\n",
    "#     new_df = add_features(table_creator(text))\n",
    "\n",
    "#     rec_list.append(new_df)\n",
    "\n",
    "# records_df = pd.concat(rec_list, axis=0)\n",
    "\n",
    "# all_process_df = feature_engineering(records_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_process_df[\"result\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# stake_teams = txt_reader(\"league_data/stake_teams.txt\")\n",
    "# new_week = int(stake_teams.split(\"\\n\")[4].split(\"WEEK\")[1].strip())\n",
    "# stake_teams = stake_teams.split(\"\\n\")[5:-9][0:31:3][1:]\n",
    "# stake_vals = []\n",
    "# for club in stake_teams:\n",
    "#     club = club.strip()\n",
    "#     h_team = club[:4]\n",
    "#     a_team = club[6:10]\n",
    "#     stake_vals.append((new_week, h_team, a_team, 0, 0))\n",
    "# stake_teams_df = pd.DataFrame(stake_vals, columns=[\"week\", \"HT\", \"AT\", \"HCS\", \"ACS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stake_teams_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARS - BUR = 0\n",
      "MNU - FOR = 0\n",
      "SHU - CRY = 0\n",
      "LUT - BRN = 0\n",
      "ASV - WHU = 0\n",
      "CHE - EVE = 0\n",
      "LIV - MNC = 0\n",
      "BRI - BOU = 0\n",
      "NWC - FUL = 0\n",
      "TOT - WOL = 1\n"
     ]
    }
   ],
   "source": [
    "teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL',\n",
    "         'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "stake_teams = txt_reader(\"league_data/stake_teams.txt\")\n",
    "new_week = int(stake_teams.split(\"\\n\")[4].split(\"WEEK\")[1].strip())\n",
    "stake_teams = stake_teams.split(\"\\n\")[5:-9][0:31:3][1:]\n",
    "stake_vals = []\n",
    "for club in stake_teams:\n",
    "    club = club.strip()\n",
    "    h_team = club[:4].strip()\n",
    "    a_team = club[6:10].strip()\n",
    "    stake_vals.append((new_week, h_team, a_team, 0, 0))\n",
    "stake_teams_df = pd.DataFrame(stake_vals, columns=[\"week\", \"HT\", \"AT\", \"HCS\", \"ACS\"])\n",
    "\n",
    "\n",
    "team_objects = [Team(team) for team in teams]\n",
    "\n",
    "stake_df = table_creator(txt_reader(\"league_data/LN_1570.txt\"))\n",
    "merge_df = pd.concat([stake_df, stake_teams_df], axis=0, ignore_index=True)\n",
    "merge_df = add_features(merge_df)\n",
    "\n",
    "process_df = feature_engineering(merge_df)\n",
    "\n",
    "pred_data = process_df.drop(\"result\", axis=1).tail(10)\n",
    "pred_vals = rf_model.predict(pred_data).tolist()\n",
    "\n",
    "home = merge_df[\"HT\"].tail(10)\n",
    "away = merge_df[\"AT\"].tail(10)\n",
    "\n",
    "for x, y, z in zip(home, away, pred_vals):\n",
    "    print(x, \"-\", y, \"=\", z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHU - MNC = 0\n",
      "FUL - LIV = 0\n",
      "TOT - NWC = 0\n",
      "BRN - BRI = 0\n",
      "FOR - MNU = 0\n",
      "ARS - CHE = 0\n",
      "LUT - BOU = 0\n",
      "CRY - EVE = 0\n",
      "ASV - SHU = 0\n",
      "WOL - BUR = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_data = process_df.drop(\"result\", axis=1).tail(10)\n",
    "pred_vals = rf_model.predict(pred_data).tolist()\n",
    "\n",
    "home = merge_df[\"HT\"].tail(10)\n",
    "away = merge_df[\"AT\"].tail(10)\n",
    "\n",
    "for x, y, z in zip(home, away, pred_vals):\n",
    "    print(x, \"-\", y, \"=\", z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# # Load your dataset into a pandas DataFrame\n",
    "# dataset = processed_df.copy()\n",
    "\n",
    "# # Load your dataset into X and y arrays\n",
    "# X = dataset.drop(\"result\", axis=1)\n",
    "# y = dataset[\"result\"]\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Define a dictionary to store the models\n",
    "# models = {\n",
    "#     'Random Forest': RandomForestClassifier(random_state=42),\n",
    "#     'SVC': SVC(random_state=42),\n",
    "#     'XGBoost': XGBClassifier(random_state=42),\n",
    "#     'Gradient Boost': GradientBoostingClassifier(random_state=42),\n",
    "#     'Logistic Regression': LogisticRegression(random_state=42),\n",
    "#     # 'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "# }\n",
    "\n",
    "# # Calculate the F1 scores for each model\n",
    "# model_scores = []\n",
    "# for model_name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "#     f1 = round(f1_score(y_test, y_pred, average='weighted'), 3)\n",
    "#     model_scores.append((model_name, f1))\n",
    "#     print(f'{model_name}:')\n",
    "#     print('Accuracy:', accuracy)\n",
    "#     print('F1 score:', f1)\n",
    "#     print('-' * 40)\n",
    "\n",
    "# # Sort the models based on F1 scores in descending order\n",
    "# model_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "# model_names, f1_scores = zip(*model_scores)\n",
    "\n",
    "# # Plot the horizontal bar graph\n",
    "# plt.figure(figsize=(12, 7))\n",
    "# plt.barh(model_names, f1_scores)  # <-- Use plt.barh() for horizontal bars\n",
    "# plt.ylabel('Model')\n",
    "# plt.xlabel('F1 Score')\n",
    "# plt.title('F1 Scores of Different Models')\n",
    "\n",
    "# # Add the scores beside each bar\n",
    "# for i, score in enumerate(f1_scores):\n",
    "#     plt.text(score, i, f'{score:.3f}', ha='left', va='center')  # <-- Adjust text position\n",
    "\n",
    "# # Display the horizontal bar graph\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
