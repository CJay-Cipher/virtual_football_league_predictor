{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIVE, FOUR, THREE, TWO, ONE, ZERO = 5, 4, 3, 2, 1, 0\n",
    "\n",
    "# data_table = pd.DataFrame(columns=[\"league_id\", \"week\", \"hour\", \"minute\", \"HT\", \"AT\", \"HCS\", \"ACS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def txt_reader(_path):\n",
    "    file = open(_path, 'r')  # Open the file in read mode\n",
    "    contents = file.read()  # Read the contents of the file\n",
    "    file.close()  # Close the file\n",
    "\n",
    "    return contents\n",
    "\n",
    "\n",
    "def table_creator(contents):\n",
    "    record_list = []\n",
    "    weeks = contents.split(\"WEEK\")\n",
    "    pos = weeks[0].index(\"League\")\n",
    "    league_no = int(weeks[0][(pos + 7): (pos + 11)])\n",
    "    for val in weeks[1:]:\n",
    "        scores = val.split(\"\\n\")[1:-1]\n",
    "        for score in scores:\n",
    "            temp_dict = {\n",
    "                \"league_id\": league_no,\n",
    "                \"week\": int((val[:3]).strip()),\n",
    "                \"hour\": int(val.split(\"\\n\")[0][-8:-6]),\n",
    "                \"minute\": int(val.split(\"\\n\")[0][-5:-3]),\n",
    "\n",
    "                \"HT\": score[0:3],\n",
    "                \"AT\": score[8:11],\n",
    "                \"HCS\": int(score[4]),\n",
    "                \"ACS\": int(score[6])\n",
    "            }\n",
    "\n",
    "            # data._append(temp_dict, ignore_index=True)\n",
    "            record_list.append(temp_dict)\n",
    "    data = pd.DataFrame(record_list)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record = txt_reader(\"sample_4.txt\")\n",
    "# df = table_creator(record)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Team:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.goals_for = 0\n",
    "        self.goals_against = 0\n",
    "        self.goal_difference = 0\n",
    "        self.points = 0\n",
    "        self.position = 0\n",
    "        self.last_results = []  # List to store last results\n",
    "        self.last_1_result = 0\n",
    "        self.last_2_result = 0\n",
    "        \n",
    "def update_table(team_1, team_1_score, team_2, team_2_score):\n",
    "    team1 = next(team for team in team_objects if team.name == team_1)\n",
    "    team2 = next(team for team in team_objects if team.name == team_2)\n",
    "\n",
    "    scores = [team_1_score, team_2_score]\n",
    "    new_teams = [team1, team2]\n",
    "\n",
    "    for i, team in enumerate(new_teams):\n",
    "        team.goals_for += scores[i]\n",
    "        team.goals_against += scores[1 - i]\n",
    "        team.goal_difference = team.goals_for - team.goals_against\n",
    "        team.points += 3 if scores[i] > scores[1 - i] else 1 if scores[i] == scores[1 - i] else 0\n",
    "        team.last_results.append(1 if scores[i] > scores[1 - i] else 0 if scores[i] == scores[1 - i] else -1)\n",
    "        team.last_1_result = team.last_results[-1]\n",
    "        team.last_2_result = team.last_results[-2] if len(team.last_results) > 1 else 0\n",
    "\n",
    "    table = sorted(team_objects, key=lambda x: (-x.points, x.name.lower()))\n",
    "\n",
    "    for i, team in enumerate(table):\n",
    "        team.position = i + 1\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def get_record(table_objects):\n",
    "    table_dict = dict()\n",
    "    for team in table_objects:\n",
    "        table_dict[team.name] = (\n",
    "            team.points,\n",
    "            team.position,\n",
    "            team.last_1_result,\n",
    "            team.last_2_result\n",
    "        )\n",
    "\n",
    "    return table_dict\n",
    "\n",
    "\n",
    "def add_features(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    col_list = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        ht, hcs, at, acs = row[\"HT\"], row[\"HCS\"], row[\"AT\"], row[\"ACS\"]\n",
    "\n",
    "        table = update_table(ht, hcs, at, acs)\n",
    "\n",
    "        if row[\"week\"] > 2:\n",
    "            col_list.append(table_dict[ht] + table_dict[at])\n",
    "        else:\n",
    "            col_list.append((0,) * 8)\n",
    "\n",
    "        if (i+1) % 20 == 0:\n",
    "            table_dict = get_record(table)\n",
    "\n",
    "    # Create a DataFrame from the list of tuples\n",
    "    new_df = pd.DataFrame(col_list, columns=[\n",
    "        \"h_pts\", \"h_pos\", \"HL1R\", \"HL2R\", \n",
    "        \"a_pts\", \"a_pos\", \"AL1R\", \"AL2R\"])\n",
    "\n",
    "    # Concatenate the new DataFrame with the existing DataFrame\n",
    "    df = pd.concat([df, new_df], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the TXT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"league_data\"\n",
    "records = [\n",
    "    f\"{path}/L_6095.txt\", f\"{path}/L_6097.txt\", f\"{path}/L_6099.txt\",\n",
    "    f\"{path}/L_6148.txt\", f\"{path}/L_6152.txt\", f\"{path}/L_6153.txt\",\n",
    "    f\"{path}/L_6155.txt\", f\"{path}/L_6156.txt\", f\"{path}/L_6166.txt\",\n",
    "    f\"{path}/L_6169.txt\", f\"{path}/L_6170.txt\", f\"{path}/L_6171.txt\",\n",
    "    f\"{path}/L_6173.txt\", f\"{path}/L_6180.txt\", f\"{path}/L_6181.txt\",\n",
    "    f\"{path}/L_6189.txt\", f\"{path}/L_6192.txt\", f\"{path}/L_6211.txt\",\n",
    "    f\"{path}/L_6212.txt\", f\"{path}/L_6213.txt\", f\"{path}/L_6214.txt\",\n",
    "    f\"{path}/L_6215.txt\", f\"{path}/L_6216.txt\", f\"{path}/L_6226.txt\", \n",
    "    f\"{path}/L_6227.txt\", f\"{path}/L_6230.txt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "#          'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "         'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "\n",
    "\n",
    "df_temp = []\n",
    "for record in records:\n",
    "    text = txt_reader(record)  # read each txt data\n",
    "    new_df = table_creator(text)  # convert each txt data to a dataframe\n",
    "    \n",
    "    # create a new empty league table to record scores & points\n",
    "    team_objects = [Team(team) for team in teams]\n",
    "\n",
    "    # adds scores & points from each league to the dataframe\n",
    "    new_df = add_features(new_df)\n",
    "\n",
    "    df_temp.append(new_df)  # add each dataframe to a list\n",
    "\n",
    "df_records = pd.concat(df_temp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league_id</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>HT</th>\n",
       "      <th>AT</th>\n",
       "      <th>HCS</th>\n",
       "      <th>ACS</th>\n",
       "      <th>h_pts</th>\n",
       "      <th>h_pos</th>\n",
       "      <th>HL1R</th>\n",
       "      <th>HL2R</th>\n",
       "      <th>a_pts</th>\n",
       "      <th>a_pos</th>\n",
       "      <th>AL1R</th>\n",
       "      <th>AL2R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>6155</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>FUL</td>\n",
       "      <td>LEE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>6155</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>EVE</td>\n",
       "      <td>CHE</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>6155</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>MNU</td>\n",
       "      <td>BRI</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     league_id  week  hour  minute   HT   AT  HCS  ACS  h_pts  h_pos  HL1R  \\\n",
       "377       6155    38    18       6  FUL  LEE    1    1     38     14    -1   \n",
       "378       6155    38    18       6  EVE  CHE    1    3     35     18     1   \n",
       "379       6155    38    18       6  MNU  BRI    2    1     48      8     0   \n",
       "\n",
       "     HL2R  a_pts  a_pos  AL1R  AL2R  \n",
       "377     1     45      9     1     1  \n",
       "378    -1     75      2     1    -1  \n",
       "379    -1     44     10     1     1  "
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_records.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_records.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_records[df_records[\"week\"] == 36].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_records[df_records[\"week\"] == 37].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_records[df_records[\"week\"] == 38].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check home and away scores and return result\n",
    "def get_result(row):\n",
    "    if row['HCS'] > row['ACS']:\n",
    "        return 1  # home_win = 1\n",
    "    elif row['HCS'] < row['ACS']:\n",
    "        return 2  # away_win = 2\n",
    "    else:\n",
    "        return 0  # draw = 0\n",
    "        \n",
    "\n",
    "def feature_engineering(data):\n",
    "    df_result = data.copy()\n",
    "        \n",
    "    # Apply function to each row of the dataframe to create a new column\n",
    "    df_result['result'] = df_result.apply(get_result, axis=1)\n",
    "\n",
    "    df_result = df_result[df_result['week'] > 2]  # remove rows with incomplete values\n",
    "\n",
    "    # Create a LabelEncoder object\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit the LabelEncoder on the unique team names\n",
    "    label_encoder.fit(teams)\n",
    "\n",
    "    # Convert the categorical features to numeric using label encoding\n",
    "    df_result['HT_encoded'] = label_encoder.transform(df_result['HT'])\n",
    "    df_result['AT_encoded'] = label_encoder.transform(df_result['AT'])\n",
    "\n",
    "    # remove irrelevant features\n",
    "    df_result = df_result.drop([\"league_id\", \"hour\", \"minute\", \"HCS\", \"ACS\", \"HT\", \"AT\"], axis=1)  \n",
    "\n",
    "    df_result = df_result.reset_index(drop=True)  # reset the index values\n",
    "\n",
    "    # Scaling the dataset using standardization method\n",
    "    X = df_result.drop(\"result\", axis=1)\n",
    "    y = df_result[\"result\"]\n",
    "\n",
    "    # assume that X is your dataset with numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # # concatenate the scaled numerical features with the Target variable feature\n",
    "    data_preprocessed = pd.concat([pd.DataFrame(X_scaled, columns=X.columns), y], axis=1)\n",
    "\n",
    "    return data_preprocessed\n",
    "\n",
    "\n",
    "processed_df = feature_engineering(df_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>h_pts</th>\n",
       "      <th>h_pos</th>\n",
       "      <th>HL1R</th>\n",
       "      <th>HL2R</th>\n",
       "      <th>a_pts</th>\n",
       "      <th>a_pos</th>\n",
       "      <th>AL1R</th>\n",
       "      <th>AL2R</th>\n",
       "      <th>HT_encoded</th>\n",
       "      <th>AT_encoded</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.684588</td>\n",
       "      <td>-1.339106</td>\n",
       "      <td>-0.262961</td>\n",
       "      <td>-1.156756</td>\n",
       "      <td>1.144610</td>\n",
       "      <td>-1.283261</td>\n",
       "      <td>-1.125762</td>\n",
       "      <td>1.155484</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>-0.607390</td>\n",
       "      <td>-1.646625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.684588</td>\n",
       "      <td>-1.456221</td>\n",
       "      <td>1.122275</td>\n",
       "      <td>0.021508</td>\n",
       "      <td>-1.180595</td>\n",
       "      <td>-1.283261</td>\n",
       "      <td>-0.952070</td>\n",
       "      <td>1.155484</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>1.127617</td>\n",
       "      <td>-0.779908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.684588</td>\n",
       "      <td>-1.339106</td>\n",
       "      <td>-0.609270</td>\n",
       "      <td>1.199772</td>\n",
       "      <td>-1.180595</td>\n",
       "      <td>-1.165949</td>\n",
       "      <td>-1.473148</td>\n",
       "      <td>1.155484</td>\n",
       "      <td>1.179962</td>\n",
       "      <td>-1.474894</td>\n",
       "      <td>0.606839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       week     h_pts     h_pos      HL1R      HL2R     a_pts     a_pos  \\\n",
       "0 -1.684588 -1.339106 -0.262961 -1.156756  1.144610 -1.283261 -1.125762   \n",
       "1 -1.684588 -1.456221  1.122275  0.021508 -1.180595 -1.283261 -0.952070   \n",
       "2 -1.684588 -1.339106 -0.609270  1.199772 -1.180595 -1.165949 -1.473148   \n",
       "\n",
       "       AL1R      AL2R  HT_encoded  AT_encoded  result  \n",
       "0  1.155484  0.017983   -0.607390   -1.646625       0  \n",
       "1  1.155484  0.017983    1.127617   -0.779908       1  \n",
       "2  1.155484  1.179962   -1.474894    0.606839       1  "
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4742063492063492\n",
      "F1 score: 0.4581324473093734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "dataset = processed_df.copy()\n",
    "\n",
    "# Load your dataset into X and y arrays\n",
    "X = dataset.drop(\"result\", axis=1)\n",
    "y = dataset[\"result\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy and F1 score of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('F1 score:', f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIN % - 89.2\n"
     ]
    }
   ],
   "source": [
    "num = 1000\n",
    "actual_vals = processed_df[\"result\"].head(num)\n",
    "\n",
    "data = processed_df.drop(\"result\", axis=1).head(num)\n",
    "pred_vals = rf_model.predict(data).tolist()\n",
    "\n",
    "count = 0\n",
    "for x, y in zip(actual_vals, pred_vals):\n",
    "    if x == y:\n",
    "        count += 1\n",
    "        \n",
    "print(\"WIN % -\", (count/num) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "         'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "# teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "#          'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "\n",
    "         \n",
    "# create a new empty league table to record scores & points\n",
    "team_objects = [Team(team) for team in teams]\n",
    "\n",
    "test_record = \"league_data/new_record.txt\"\n",
    "df_new = []\n",
    "\n",
    "text = txt_reader(test_record)  # read each txt data\n",
    "\n",
    "# adds scores & points from each league to the dataframe\n",
    "new_df = add_features(table_creator(text))\n",
    "\n",
    "df_new.append(new_df)  # add each dataframe to a list\n",
    "\n",
    "records_df = pd.concat(df_new, axis=0)\n",
    "\n",
    "process_df = feature_engineering(records_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270,)"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df[\"result\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Win Count: 7 / 20 \n",
      "WIN % - 35.0\n"
     ]
    }
   ],
   "source": [
    "num = 20\n",
    "actual_vals = process_df[\"result\"].head(num)\n",
    "\n",
    "data = process_df.drop(\"result\", axis=1).head(num)\n",
    "pred_vals = rf_model.predict(data).tolist()\n",
    "\n",
    "count = 0\n",
    "for x, y in zip(actual_vals, pred_vals):\n",
    "    if x == y:\n",
    "        # print(x, \"-->\", y, \"WIN\")\n",
    "        count += 1\n",
    "    # else:\n",
    "    #     print(x, \"-->\", y)\n",
    "\n",
    "        \n",
    "print(\"Total Win Count:\", count, \"/\", num, \"\\nWIN % -\", (count/num) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9880, 44)"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_record = pd.read_csv(\"league_record.csv\")\n",
    "league_record.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['league_id',\n",
       " 'week',\n",
       " 'hour',\n",
       " 'minutes',\n",
       " 'HT',\n",
       " 'AT',\n",
       " 'HCS',\n",
       " 'ACS',\n",
       " 'HL1S',\n",
       " 'AL1S',\n",
       " 'HL2S',\n",
       " 'AL2S',\n",
       " 'HL3S',\n",
       " 'AL3S',\n",
       " 'hl1_stat',\n",
       " 'al1_stat',\n",
       " 'hl2_stat',\n",
       " 'al2_stat',\n",
       " 'hl3_stat',\n",
       " 'al3_stat',\n",
       " 'h_wins',\n",
       " 'a_wins',\n",
       " 'h_draws',\n",
       " 'a_draws',\n",
       " 'h_loss',\n",
       " 'a_loss',\n",
       " 'h_gf',\n",
       " 'a_gf',\n",
       " 'h_ga',\n",
       " 'a_ga',\n",
       " 'h_gd',\n",
       " 'a_gd',\n",
       " 'hs_avg',\n",
       " 'as_avg',\n",
       " 'hw_rat',\n",
       " 'aw_rat',\n",
       " 'hl_rat',\n",
       " 'al_rat',\n",
       " 'hd_rat',\n",
       " 'ad_rat',\n",
       " 'ht_points',\n",
       " 'at_points',\n",
       " 'ht_pos',\n",
       " 'at_pos']"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "league_record.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
