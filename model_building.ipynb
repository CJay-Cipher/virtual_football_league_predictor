{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas to display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>HT</th>\n",
       "      <th>AT</th>\n",
       "      <th>home</th>\n",
       "      <th>draw</th>\n",
       "      <th>away</th>\n",
       "      <th>over_1</th>\n",
       "      <th>under_1</th>\n",
       "      <th>over_2</th>\n",
       "      <th>under_2</th>\n",
       "      <th>over_3</th>\n",
       "      <th>under_3</th>\n",
       "      <th>over_4</th>\n",
       "      <th>under_4</th>\n",
       "      <th>H_score</th>\n",
       "      <th>A_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>EVE</td>\n",
       "      <td>BRN</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.59</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.93</td>\n",
       "      <td>1.87</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1.31</td>\n",
       "      <td>7.99</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>MNC</td>\n",
       "      <td>ASV</td>\n",
       "      <td>1.57</td>\n",
       "      <td>4.03</td>\n",
       "      <td>6.02</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.43</td>\n",
       "      <td>6.09</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>FOR</td>\n",
       "      <td>FUL</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>MNU</td>\n",
       "      <td>WOL</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5.32</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.42</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>SHU</td>\n",
       "      <td>LUT</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.07</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.37</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.29</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>21</td>\n",
       "      <td>EVE</td>\n",
       "      <td>WOL</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1.31</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>21</td>\n",
       "      <td>MNU</td>\n",
       "      <td>CRY</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5.32</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.42</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>21</td>\n",
       "      <td>SHU</td>\n",
       "      <td>BOU</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.22</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>21</td>\n",
       "      <td>BRN</td>\n",
       "      <td>NWC</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.28</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.31</td>\n",
       "      <td>7.94</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>21</td>\n",
       "      <td>FUL</td>\n",
       "      <td>MNC</td>\n",
       "      <td>7.60</td>\n",
       "      <td>4.66</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.58</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.44</td>\n",
       "      <td>5.83</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6090 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      week   HT   AT  home  draw  away  over_1  under_1  over_2  under_2  \\\n",
       "0       21  EVE  BRN  2.88  3.14  2.59    1.29     3.62    1.93     1.87   \n",
       "1       21  MNC  ASV  1.57  4.03  6.02    1.20     4.56    1.69     2.17   \n",
       "2       21  FOR  FUL  2.29  3.02  3.53    1.33     3.35    2.07     1.75   \n",
       "3       21  MNU  WOL  1.77  3.33  5.32    1.22     4.33    1.74     2.09   \n",
       "4       21  SHU  LUT  2.24  3.07  3.58    1.32     3.37    2.07     1.76   \n",
       "...    ...  ...  ...   ...   ...   ...     ...      ...     ...      ...   \n",
       "6085    21  EVE  WOL  2.45  3.19  3.03    1.29     3.61    1.94     1.86   \n",
       "6086    21  MNU  CRY  1.77  3.33  5.32    1.22     4.33    1.74     2.09   \n",
       "6087    21  SHU  BOU  2.43  3.24  3.01    1.33     3.31    2.07     1.76   \n",
       "6088    21  BRN  NWC  2.88  3.23  2.53    1.28     3.68    1.92     1.88   \n",
       "6089    21  FUL  MNC  7.60  4.66  1.42    1.20     4.58    1.65     2.24   \n",
       "\n",
       "      over_3  under_3  over_4  under_4  H_score  A_score  \n",
       "0       3.42     1.31    7.99     1.08        3        2  \n",
       "1       2.84     1.43    6.09     1.12        1        1  \n",
       "2       3.76     1.27    9.27     1.06        2        3  \n",
       "3       2.87     1.42    6.36     1.12        1        0  \n",
       "4       3.76     1.27    9.29     1.06        0        1  \n",
       "...      ...      ...     ...      ...      ...      ...  \n",
       "6085    3.45     1.31    8.00     1.08        0        0  \n",
       "6086    2.87     1.42    6.36     1.12        2        2  \n",
       "6087    3.85     1.26    9.22     1.06        0        0  \n",
       "6088    3.43     1.31    7.94     1.08        0        1  \n",
       "6089    2.80     1.44    5.83     1.13        0        0  \n",
       "\n",
       "[6090 rows x 16 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data 5 is baddest and 9 is largest\n",
    "\n",
    "df = pd.read_csv(\"odds_datas/test_9_odds_data.csv\") # odds_data\n",
    "df.rename(columns={\"HT.1\": 'AT'}, inplace=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"odds_datas\"\n",
    "# records = [\n",
    "#     f\"{path}/test_1_odds_data.csv\", f\"{path}/test_2_odds_data.csv\", f\"{path}/test_3_odds_data.csv\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Team:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.goals_for = 0\n",
    "        self.goals_against = 0\n",
    "        self.goal_difference = 0\n",
    "        self.points = 0\n",
    "        self.position = 0\n",
    "        self.last_results = []  # List to store last results\n",
    "        self.last_1_result = 0\n",
    "        self.last_2_result = 0\n",
    "        \n",
    "def update_table(team_1, team_1_score, team_2, team_2_score):\n",
    "    team1 = next(team for team in team_objects if team.name == team_1)\n",
    "    team2 = next(team for team in team_objects if team.name == team_2)\n",
    "\n",
    "    scores = [team_1_score, team_2_score]\n",
    "    new_teams = [team1, team2]\n",
    "\n",
    "    for i, team in enumerate(new_teams):\n",
    "        team.goals_for += scores[i]\n",
    "        team.goals_against += scores[1 - i]\n",
    "        team.goal_difference = team.goals_for - team.goals_against\n",
    "        team.points += 3 if scores[i] > scores[1 - i] else 1 if scores[i] == scores[1 - i] else 0\n",
    "        team.last_results.append(1 if scores[i] > scores[1 - i] else 0 if scores[i] == scores[1 - i] else -1)\n",
    "        team.last_1_result = team.last_results[-1]\n",
    "        team.last_2_result = team.last_results[-2] if len(team.last_results) > 1 else 0\n",
    "\n",
    "    table = sorted(team_objects, key=lambda x: (-x.points, x.name.lower()))\n",
    "\n",
    "    for i, team in enumerate(table):\n",
    "        team.position = i + 1\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def get_record(table_objects):\n",
    "    table_dict = dict()\n",
    "    for team in table_objects:\n",
    "        table_dict[team.name] = (\n",
    "            team.points,\n",
    "            team.position,\n",
    "            team.last_1_result,\n",
    "            # team.last_2_result,\n",
    "            # team.goals_for,\n",
    "            # team.goals_against,\n",
    "            team.goal_difference\n",
    "        )\n",
    "\n",
    "    return table_dict\n",
    "\n",
    "\n",
    "def add_features(data):\n",
    "    dff = data.copy()\n",
    "    # print(dff.shape)\n",
    "\n",
    "    col_list = []\n",
    "\n",
    "    for i, row in dff.iterrows():\n",
    "        ht, hcs, at, acs = row[\"HT\"], row[\"H_score\"], row[\"AT\"], row[\"A_score\"]\n",
    "\n",
    "        table = update_table(ht, hcs, at, acs)\n",
    "\n",
    "        if row[\"week\"] > 2:\n",
    "            val = table_dict[ht] + table_dict[at]\n",
    "        else:\n",
    "            val = (0,) * 8\n",
    "        col_list.append(val)\n",
    "        # print(val)\n",
    "\n",
    "        if (i+1) % 20 == 0:\n",
    "            table_dict = get_record(table)\n",
    "\n",
    "    return col_list\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Define function to check home and away scores and return result\n",
    "def get_result(row):\n",
    "    # if row['H_score'] > row['A_score']:\n",
    "    #     return 1  # home_win = 1\n",
    "    # elif row['H_score'] < row['A_score']:\n",
    "    #     return 2  # away_win = 2\n",
    "    # else:\n",
    "    #     return 0  # draw = 0\n",
    "    \n",
    "    if row[\"H_score\"] + row[\"A_score\"] < 4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def feature_engineering(data):\n",
    "    df_result = data.copy()\n",
    "        \n",
    "    # Apply function to each row of the dataframe to create a new column\n",
    "    df_result['result'] = df_result.apply(get_result, axis=1)\n",
    "\n",
    "    df_result = df_result[df_result['week'] > 2]  # remove rows with incomplete values\n",
    "\n",
    "    # Create a LabelEncoder object\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Fit the LabelEncoder on the unique team names\n",
    "    label_encoder.fit(teams)\n",
    "\n",
    "    # Convert the categorical features to numeric using label encoding\n",
    "    df_result['HT_encoded'] = label_encoder.transform(df_result['HT'])\n",
    "    df_result['AT_encoded'] = label_encoder.transform(df_result['AT'])\n",
    "\n",
    "    # remove irrelevant features\n",
    "    df_result = df_result.drop([\"H_score\", \"A_score\", \"HT\", \"AT\"], axis=1)\n",
    "\n",
    "    df_result = df_result.reset_index(drop=True)  # reset the index values\n",
    "\n",
    "    # # Scaling the dataset using standardization method\n",
    "    # X = df_result.drop(\"result\", axis=1)\n",
    "    # y = df_result[\"result\"]\n",
    "\n",
    "    # # assume that X is your dataset with numerical features\n",
    "    # scaler = StandardScaler()\n",
    "    # X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # # # concatenate the scaled numerical features with the Target variable feature\n",
    "    # data_preprocessed = pd.concat([pd.DataFrame(X_scaled, columns=X.columns), y], axis=1)\n",
    "\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>HT</th>\n",
       "      <th>AT</th>\n",
       "      <th>home</th>\n",
       "      <th>draw</th>\n",
       "      <th>away</th>\n",
       "      <th>over_1</th>\n",
       "      <th>under_1</th>\n",
       "      <th>over_2</th>\n",
       "      <th>under_2</th>\n",
       "      <th>over_3</th>\n",
       "      <th>under_3</th>\n",
       "      <th>over_4</th>\n",
       "      <th>under_4</th>\n",
       "      <th>H_score</th>\n",
       "      <th>A_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BRI</td>\n",
       "      <td>LUT</td>\n",
       "      <td>1.46</td>\n",
       "      <td>4.36</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.04</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1.37</td>\n",
       "      <td>6.73</td>\n",
       "      <td>1.10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>WHU</td>\n",
       "      <td>SHU</td>\n",
       "      <td>1.55</td>\n",
       "      <td>4.05</td>\n",
       "      <td>6.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.93</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.33</td>\n",
       "      <td>7.45</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MNU</td>\n",
       "      <td>CRY</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5.32</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4.33</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.87</td>\n",
       "      <td>1.42</td>\n",
       "      <td>6.36</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>FUL</td>\n",
       "      <td>BOU</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>FOR</td>\n",
       "      <td>MNC</td>\n",
       "      <td>7.60</td>\n",
       "      <td>4.66</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.58</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.44</td>\n",
       "      <td>5.83</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>38</td>\n",
       "      <td>BUR</td>\n",
       "      <td>CHE</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.04</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.39</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696</th>\n",
       "      <td>38</td>\n",
       "      <td>MNC</td>\n",
       "      <td>BRN</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.38</td>\n",
       "      <td>7.03</td>\n",
       "      <td>1.18</td>\n",
       "      <td>4.86</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.48</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5697</th>\n",
       "      <td>38</td>\n",
       "      <td>WOL</td>\n",
       "      <td>LIV</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.24</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.13</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5698</th>\n",
       "      <td>38</td>\n",
       "      <td>EVE</td>\n",
       "      <td>LUT</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>38</td>\n",
       "      <td>FOR</td>\n",
       "      <td>BOU</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5700 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      week   HT   AT  home  draw  away  over_1  under_1  over_2  under_2  \\\n",
       "0        1  BRI  LUT  1.46  4.36  7.20    1.23     4.13    1.78     2.04   \n",
       "1        1  WHU  SHU  1.55  4.05  6.24    1.26     3.83    1.87     1.93   \n",
       "2        1  MNU  CRY  1.77  3.33  5.32    1.22     4.33    1.74     2.09   \n",
       "3        1  FUL  BOU  2.29  3.02  3.53    1.33     3.35    2.07     1.75   \n",
       "4        1  FOR  MNC  7.60  4.66  1.42    1.20     4.58    1.65     2.24   \n",
       "...    ...  ...  ...   ...   ...   ...     ...      ...     ...      ...   \n",
       "5695    38  BUR  CHE  4.38  3.33  1.91    1.23     4.16    1.78     2.04   \n",
       "5696    38  MNC  BRN  1.47  4.38  7.03    1.18     4.86    1.61     2.31   \n",
       "5697    38  WOL  LIV  3.70  3.07  2.19    1.24     4.10    1.83     1.98   \n",
       "5698    38  EVE  LUT  1.95  3.29  4.25    1.33     3.33    2.08     1.75   \n",
       "5699    38  FOR  BOU  2.29  3.02  3.53    1.33     3.35    2.07     1.75   \n",
       "\n",
       "      over_3  under_3  over_4  under_4  H_score  A_score  \n",
       "0       3.09     1.37    6.73     1.10        4        0  \n",
       "1       3.32     1.33    7.45     1.09        1        2  \n",
       "2       2.87     1.42    6.36     1.12        1        2  \n",
       "3       3.76     1.27    9.27     1.06        0        0  \n",
       "4       2.80     1.44    5.83     1.13        2        0  \n",
       "...      ...      ...     ...      ...      ...      ...  \n",
       "5695    3.01     1.39    6.74     1.10        2        1  \n",
       "5696    2.64     1.48    5.44     1.15        2        0  \n",
       "5697    3.08     1.37    7.13     1.09        0        3  \n",
       "5698    3.83     1.26    9.27     1.06        2        0  \n",
       "5699    3.76     1.27    9.27     1.06        1        3  \n",
       "\n",
       "[5700 rows x 16 columns]"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = df.copy()\n",
    "df_encoded = df_encoded.iloc[180: 5880]\n",
    "df_encoded = df_encoded.reset_index(drop=True)\n",
    "\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_new = []\n",
    "\n",
    "split_num = 380\n",
    "\n",
    "total_seasons = len(df_encoded) // split_num\n",
    "# print(\"Total Seasons -\", total_seasons)\n",
    "start = 0\n",
    "end = split_num\n",
    "for _ in range(total_seasons):\n",
    "    # print(start, end)\n",
    "    df_temp = df_encoded.iloc[start: end].copy()\n",
    "\n",
    "    teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL', \n",
    "             'NWC', 'BOU', 'BUR', 'LIV', 'WOL', 'MNU', 'LUT', 'SHU', 'BRI', 'CRY']\n",
    "\n",
    "    # teams = ['FOR', 'MNC', 'ASV', 'TOT', 'EVE', 'CHE', 'BRN', 'WHU', 'ARS', 'FUL',\n",
    "    #          'NWC', 'BOU', 'LEI', 'LIV', 'WOL', 'MNU', 'LEE', 'SOU', 'BRI', 'CRY']\n",
    "            \n",
    "    # create a new empty league table to record scores & points\n",
    "    team_objects = [Team(team) for team in teams]\n",
    "\n",
    "\n",
    "    # adds scores & points from each league to the dataframe\n",
    "    new_df = add_features(df_temp)\n",
    "    # print(new_df)\n",
    "    df_new += new_df  # add each dataframe to a list\n",
    "\n",
    "    start += split_num\n",
    "    end += split_num\n",
    "\n",
    "cols = [\"h_pts\", \"h_pos\", \"HL1R\", \"h_gd\",\n",
    "        \"a_pts\", \"a_pos\", \"AL1R\", \"a_gd\"]\n",
    "records_df = pd.DataFrame(df_new, columns=cols)\n",
    "records_df = pd.concat([df_encoded, records_df], axis=1)\n",
    "# records_df\n",
    "\n",
    "process_df = feature_engineering(records_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>home</th>\n",
       "      <th>draw</th>\n",
       "      <th>away</th>\n",
       "      <th>over_1</th>\n",
       "      <th>under_1</th>\n",
       "      <th>over_2</th>\n",
       "      <th>under_2</th>\n",
       "      <th>over_3</th>\n",
       "      <th>under_3</th>\n",
       "      <th>over_4</th>\n",
       "      <th>under_4</th>\n",
       "      <th>h_pts</th>\n",
       "      <th>h_pos</th>\n",
       "      <th>HL1R</th>\n",
       "      <th>h_gd</th>\n",
       "      <th>a_pts</th>\n",
       "      <th>a_pos</th>\n",
       "      <th>AL1R</th>\n",
       "      <th>a_gd</th>\n",
       "      <th>result</th>\n",
       "      <th>HT_encoded</th>\n",
       "      <th>AT_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.29</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.47</td>\n",
       "      <td>1.31</td>\n",
       "      <td>8.41</td>\n",
       "      <td>1.07</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.62</td>\n",
       "      <td>4.90</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.21</td>\n",
       "      <td>4.45</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.42</td>\n",
       "      <td>5.92</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.48</td>\n",
       "      <td>3.20</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.26</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.34</td>\n",
       "      <td>7.53</td>\n",
       "      <td>1.09</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>38</td>\n",
       "      <td>4.38</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.04</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.39</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.10</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>-17</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>38</td>\n",
       "      <td>1.47</td>\n",
       "      <td>4.38</td>\n",
       "      <td>7.03</td>\n",
       "      <td>1.18</td>\n",
       "      <td>4.86</td>\n",
       "      <td>1.61</td>\n",
       "      <td>2.31</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1.48</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1.15</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>38</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.24</td>\n",
       "      <td>4.10</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.98</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.13</td>\n",
       "      <td>1.09</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>38</td>\n",
       "      <td>1.95</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.25</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1.26</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>-25</td>\n",
       "      <td>39</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "      <td>-23</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5399</th>\n",
       "      <td>38</td>\n",
       "      <td>2.29</td>\n",
       "      <td>3.02</td>\n",
       "      <td>3.53</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>9.27</td>\n",
       "      <td>1.06</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>-22</td>\n",
       "      <td>38</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>-19</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5400 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      week  home  draw  away  over_1  under_1  over_2  under_2  over_3  \\\n",
       "0        3  2.29  3.00  3.54    1.29     3.60    1.97     1.83    3.47   \n",
       "1        3  1.95  3.29  4.25    1.33     3.33    2.08     1.75    3.83   \n",
       "2        3  8.62  4.90  1.36    1.21     4.45    1.67     2.20    2.85   \n",
       "3        3  1.95  3.29  4.25    1.33     3.33    2.08     1.75    3.83   \n",
       "4        3  2.48  3.20  2.98    1.26     3.83    1.88     1.92    3.26   \n",
       "...    ...   ...   ...   ...     ...      ...     ...      ...     ...   \n",
       "5395    38  4.38  3.33  1.91    1.23     4.16    1.78     2.04    3.01   \n",
       "5396    38  1.47  4.38  7.03    1.18     4.86    1.61     2.31    2.64   \n",
       "5397    38  3.70  3.07  2.19    1.24     4.10    1.83     1.98    3.08   \n",
       "5398    38  1.95  3.29  4.25    1.33     3.33    2.08     1.75    3.83   \n",
       "5399    38  2.29  3.02  3.53    1.33     3.35    2.07     1.75    3.76   \n",
       "\n",
       "      under_3  over_4  under_4  h_pts  h_pos  HL1R  h_gd  a_pts  a_pos  AL1R  \\\n",
       "0        1.31    8.41     1.07      3     12     1    -2      6      3     1   \n",
       "1        1.26    9.27     1.06      1     17    -1    -1      4      6     0   \n",
       "2        1.42    5.92     1.13      1     15    -1    -1      0     20    -1   \n",
       "3        1.26    9.27     1.06      1     16     0    -1      0     19    -1   \n",
       "4        1.34    7.53     1.09      3      7    -1     3      6      5     1   \n",
       "...       ...     ...      ...    ...    ...   ...   ...    ...    ...   ...   \n",
       "5395     1.39    6.74     1.10     36     18     0   -17     47     11    -1   \n",
       "5396     1.48    5.44     1.15     67      2     0    30     53      8     0   \n",
       "5397     1.37    7.13     1.09     40     15     0   -10     60      4     1   \n",
       "5398     1.26    9.27     1.06     31     19     1   -25     39     16    -1   \n",
       "5399     1.27    9.27     1.06     31     20     1   -22     38     17     0   \n",
       "\n",
       "      a_gd  result  HT_encoded  AT_encoded  \n",
       "0        2       1          19           7  \n",
       "1        1       1          10          16  \n",
       "2       -4       1           5          13  \n",
       "3       -5       0           8          12  \n",
       "4        5       1           3          15  \n",
       "...    ...     ...         ...         ...  \n",
       "5395     7       1           5           6  \n",
       "5396     4       1          13           4  \n",
       "5397    11       1          19          11  \n",
       "5398   -23       1           8          12  \n",
       "5399   -19       0           9           2  \n",
       "\n",
       "[5400 rows x 23 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week          0\n",
       "home          0\n",
       "draw          0\n",
       "away          0\n",
       "over_1        0\n",
       "under_1       0\n",
       "over_2        0\n",
       "under_2       0\n",
       "over_3        0\n",
       "under_3       0\n",
       "over_4        0\n",
       "under_4       0\n",
       "h_pts         0\n",
       "h_pos         0\n",
       "HL1R          0\n",
       "h_gd          0\n",
       "a_pts         0\n",
       "a_pos         0\n",
       "AL1R          0\n",
       "a_gd          0\n",
       "result        0\n",
       "HT_encoded    0\n",
       "AT_encoded    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicate Values: 0\n"
     ]
    }
   ],
   "source": [
    "duplicates = process_df[process_df.duplicated()].shape[0]\n",
    "\n",
    "print(\"Total Duplicate Values:\", duplicates)\n",
    "\n",
    "# # Dropping duplicate values\n",
    "# df_encoded.drop_duplicates(inplace=True)\n",
    "# df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# over_number = 2\n",
    "# lable = f\"over_{over_number}_result\"\n",
    "\n",
    "# df[\"total\"] = df[\"H_score\"] + df[\"A_score\"]\n",
    "# df[lable] = np.where(df['total'] > over_number, 1, 0)\n",
    "# # df = df.drop([\"H_score\", \"A_score\", \"total\"], axis=1)\n",
    "\n",
    "# df_encoded = df.copy()\n",
    "# df_encoded = df_encoded.drop([\"HT\", \"AT\", \"H_score\", \"A_score\", \"total\"], axis=1)\n",
    "\n",
    "# # df_encoded = pd.get_dummies(df, columns=['HT', 'AT'])\n",
    "# # df_encoded.replace({True: 1, False: 0}, inplace=True)\n",
    "\n",
    "# df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.6731481481481482\n",
      "F1 score: 0.6013115745003936\n",
      "------------------------------ \n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.7037037037037037\n",
      "F1 score: 0.5813204508856683\n",
      "------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CJay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Support Vector Machine\n",
      "Accuracy: 0.7037037037037037\n",
      "F1 score: 0.5813204508856683\n",
      "------------------------------ \n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.6268518518518519\n",
      "F1 score: 0.5991061922560393\n",
      "------------------------------ \n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.5861111111111111\n",
      "F1 score: 0.589786590511229\n",
      "------------------------------ \n",
      "\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.600925925925926\n",
      "F1 score: 0.5956197289082809\n",
      "------------------------------ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CJay\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Multi-layer Perceptron\n",
      "Accuracy: 0.6851851851851852\n",
      "F1 score: 0.5992256486083646\n",
      "------------------------------ \n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.6907407407407408\n",
      "F1 score: 0.5797912327324092\n",
      "------------------------------ \n",
      "\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.700925925925926\n",
      "F1 score: 0.5881919138624119\n",
      "------------------------------ \n",
      "\n",
      "Model: XGBoost\n",
      "Accuracy: 0.6481481481481481\n",
      "F1 score: 0.6085864172947673\n",
      "------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lable = \"result\"\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = process_df.drop(lable, axis=1)\n",
    "y = process_df[lable]\n",
    "\n",
    "# Standardize the features using StandardScaler before splitting\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a dictionary to store the models and their names\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Support Vector Machine': SVC(random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Multi-layer Perceptron': MLPClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Test each model and print the accuracy and F1 score\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate the accuracy and F1 score of the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('F1 score:', f1)\n",
    "    print('-' * 30, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Random Forest\n",
    "# Accuracy: 0.5101851851851852\n",
    "# F1 score: 0.507061670435882\n",
    "\n",
    "# Model: XGBoost\n",
    "# Accuracy: 0.5342592592592592\n",
    "# F1 score: 0.5323126041908798"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Random Forest\n",
    "# Accuracy: 0.590311986863711\n",
    "# F1 score: 0.5817079497014717\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Logistic Regression\n",
    "# Accuracy: 0.7003284072249589\n",
    "# F1 score: 0.5769001751452342\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Support Vector Machine\n",
    "# Accuracy: 0.7003284072249589\n",
    "# F1 score: 0.5769001751452342\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: K-Nearest Neighbors\n",
    "# Accuracy: 0.6182266009852216\n",
    "# F1 score: 0.5929422105742812\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Decision Tree\n",
    "# Accuracy: 0.5919540229885057\n",
    "# F1 score: 0.5711342576228249\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Gaussian Naive Bayes\n",
    "# Accuracy: 0.6116584564860427\n",
    "# F1 score: 0.6019015252836162\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Multi-layer Perceptron\n",
    "# Accuracy: 0.7003284072249589\n",
    "# F1 score: 0.5769001751452342\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Gradient Boosting\n",
    "# Accuracy: 0.6978653530377669\n",
    "# F1 score: 0.583027435177162\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: AdaBoost\n",
    "# Accuracy: 0.7003284072249589\n",
    "# F1 score: 0.5769001751452342\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: XGBoost\n",
    "# Accuracy: 0.6182266009852216\n",
    "# F1 score: 0.5889138400869722\n",
    "# ------------------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Random Forest\n",
    "# Accuracy: 0.5073891625615764\n",
    "# F1 score: 0.5062100408762183\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Logistic Regression\n",
    "# Accuracy: 0.5287356321839081\n",
    "# F1 score: 0.4957123651030123\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Support Vector Machine\n",
    "# Accuracy: 0.5336617405582923\n",
    "# F1 score: 0.466537283013197\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: K-Nearest Neighbors\n",
    "# Accuracy: 0.5016420361247947\n",
    "# F1 score: 0.49909559609812915\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Decision Tree\n",
    "# Accuracy: 0.4967159277504105\n",
    "# F1 score: 0.4968126153522162\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Gaussian Naive Bayes\n",
    "# Accuracy: 0.5262725779967159\n",
    "# F1 score: 0.5233768995360785\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Multi-layer Perceptron\n",
    "# Accuracy: 0.5344827586206896\n",
    "# F1 score: 0.5161139404531753\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: Gradient Boosting\n",
    "# Accuracy: 0.5402298850574713\n",
    "# F1 score: 0.5336910561690722\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: AdaBoost\n",
    "# Accuracy: 0.5451559934318555\n",
    "# F1 score: 0.5341392606141279\n",
    "# ------------------------------ \n",
    "\n",
    "# Model: XGBoost\n",
    "# Accuracy: 0.5090311986863711\n",
    "# F1 score: 0.5057990955051651\n",
    "# ------------------------------ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
